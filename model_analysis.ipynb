{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fscrZhs0d9w"
      },
      "source": [
        "Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrZ_L0Br0Z3q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# PyTorch, Lightning, timm, torchvision, shap, grad-cam, scikit-learn, pandas, matplotlib\n",
        "!pip install torch torchvision timm pytorch-lightning pytorch-gradcam shap scikit-learn pandas matplotlib grad-cam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KQ9r9gf0hER"
      },
      "source": [
        "Импорты и директории"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSuq8LGF0jDL"
      },
      "outputs": [],
      "source": [
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import pytorch_lightning as pl\n",
        "import timm\n",
        "from sklearn.svm import SVR\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
        "\n",
        "# папки для моделей и результатов\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVrXcoP90sJw"
      },
      "source": [
        "Конфигурация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrWscCnC45Wc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Diplom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "472ec4c9"
      },
      "outputs": [],
      "source": [
        "# === Настраиваемый путь к CSV и изображениям===\n",
        "# Файл должен содержать колонку 'new_filename' и 13 признаков (от 0.0 до 10.0)\n",
        "CSV_PATH = 'CoRE_Dataset/unified_dataset.csv'\n",
        "IMG_DIR = 'CoRE_Dataset/images/'\n",
        "\n",
        "# === Гиперпараметры ===\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224\n",
        "LR = 1e-4\n",
        "MAX_EPOCHS = 30\n",
        "\n",
        "# === Опции балансировки ===\n",
        "loss_type = \"class_balanced\"            # или \"mse\"\n",
        "loss_weighting_strategy = \"gradnorm\"    # или None\n",
        "use_class_aware_augmentation = True\n",
        "use_class_aware_sampler = True\n",
        "use_oversampling = True\n",
        "oversample_factor = 2.0\n",
        "rare_class_threshold = 0.05\n",
        "\n",
        "print(f'🔄 CSV путь: {CSV_PATH}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7752698"
      },
      "outputs": [],
      "source": [
        "# === Расширенная конфигурация ===\n",
        "TRAIN_MODELS = True\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Используем устройство: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umJhaoi50zvV"
      },
      "source": [
        "DataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8s5SPIc0yye"
      },
      "outputs": [],
      "source": [
        "class CompositionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset для изображений и их 13 композиционных оценок.\n",
        "    Ожидается DataFrame с колонками: 'new_filename' + 13 float-оценок.\n",
        "    \"\"\"\n",
        "    def __init__(self, df: pd.DataFrame, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_paths = df['new_filename'].values\n",
        "        self.targets = df.iloc[:, 1:].astype(np.float32).values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except (FileNotFoundError, OSError) as e:\n",
        "            print(f\"⚠️ Пропущен файл: {img_path} — {e}\")\n",
        "            # возвращаем случайное корректное изображение вместо сбоя\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(self.targets[idx])\n",
        "\n",
        "\n",
        "class CompositionDataModule(pl.LightningDataModule):\n",
        "    \"\"\"\n",
        "    PyTorch Lightning DataModule для подготовки train/val/test с поддержкой:\n",
        "    - class-aware аугментаций\n",
        "    - class-aware sampler\n",
        "    - oversampling по редким правилам\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_path: str, img_size: int, batch_size: int):\n",
        "        super().__init__()\n",
        "        self.csv_path = csv_path\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        df['new_filename'] = df['new_filename'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
        "\n",
        "        # Оставляем только 'new_filename' + 13 оценок\n",
        "        rule_columns = [\n",
        "            \"center\", \"curved\", \"diagonal\", \"fill_the_frame\", \"pattern\",\n",
        "            \"rule_of_thirds\", \"symmetric\", \"triangle\", \"vanishing_point\",\n",
        "            \"golden_ratio\", \"horizontal\", \"radial\", \"vertical\"\n",
        "        ]\n",
        "        df = df[[\"new_filename\"] + rule_columns]\n",
        "        print(f\"✅ Загружено {len(df)} изображений с 13 правилами композиции.\")\n",
        "\n",
        "        # Три раздела: train/val/test (60/20/20)\n",
        "        df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "        N = len(df)\n",
        "        n_train = int(0.6 * N)\n",
        "        n_val = int(0.2 * N)\n",
        "        self.df_train = df[:n_train]\n",
        "        self.df_val = df[n_train:n_train + n_val]\n",
        "        self.df_test = df[n_train + n_val:]\n",
        "        print(f\"📊 Split: train={len(self.df_train)}, val={len(self.df_val)}, test={len(self.df_test)}\")\n",
        "\n",
        "        # Transforms\n",
        "        train_tf = [T.RandomResizedCrop(self.img_size)]\n",
        "        if use_class_aware_augmentation:\n",
        "            train_tf += [T.ColorJitter(0.4, 0.4, 0.4, 0.1)]\n",
        "        train_tf += [T.RandomHorizontalFlip(), T.ToTensor()]\n",
        "        self.tf_train = T.Compose(train_tf)\n",
        "        self.tf_val = T.Compose([\n",
        "            T.Resize(self.img_size),\n",
        "            T.CenterCrop(self.img_size),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.ds_train = CompositionDataset(self.df_train, transform=self.tf_train)\n",
        "        self.ds_val   = CompositionDataset(self.df_val, transform=self.tf_val)\n",
        "        self.ds_test  = CompositionDataset(self.df_test, transform=self.tf_val)\n",
        "\n",
        "        # Class-aware oversampling по редким правилам\n",
        "        if use_oversampling:\n",
        "            binary_labels = (self.df_train.iloc[:, 1:] > 0).astype(int)\n",
        "            freq = binary_labels.mean()\n",
        "            rare = freq < rare_class_threshold\n",
        "            weights = []\n",
        "            for row in binary_labels.values:\n",
        "                w = 1.0\n",
        "                if any(row[rare.values]):\n",
        "                    w *= oversample_factor\n",
        "                weights.append(w)\n",
        "            self.train_sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "            print(f\"🔁 Используется oversampling с rare_class_threshold={rare_class_threshold}\")\n",
        "        else:\n",
        "            self.train_sampler = None\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.ds_train, batch_size=self.batch_size,\n",
        "                          shuffle=self.train_sampler is None,\n",
        "                          sampler=self.train_sampler, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.ds_val, batch_size=self.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.ds_test, batch_size=self.batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzwk2OWG05St"
      },
      "source": [
        "Общий LightningModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a564443"
      },
      "outputs": [],
      "source": [
        "class CompositionLitModel(pl.LightningModule):\n",
        "    def __init__(self, backbone_name, lr, num_tasks=13, task_type='regression',\n",
        "                 loss_type='default', loss_weighting_strategy=None):\n",
        "        \"\"\"\n",
        "        task_type: 'regression', 'classification', 'both'\n",
        "        loss_type: 'default' or 'class_balanced'\n",
        "        loss_weighting_strategy: None or 'gradnorm'\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.task_type = task_type\n",
        "        self.lr = lr\n",
        "        self.loss_type = loss_type\n",
        "        self.loss_weighting_strategy = loss_weighting_strategy\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Backbone\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0, global_pool='avg')\n",
        "        feat_dim = self.backbone.num_features\n",
        "\n",
        "        # Heads\n",
        "        if task_type in ['regression', 'both']:\n",
        "            # Выход с сигмоидой: всегда в [0, 1] -> *10 => [0, 10]\n",
        "            self.reg_heads = nn.ModuleList([\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(feat_dim, 1),\n",
        "                    nn.Sigmoid()  # Строго [0, 1]\n",
        "                ) for _ in range(num_tasks)\n",
        "            ])\n",
        "            self.mse = nn.MSELoss()\n",
        "        else:\n",
        "            self.reg_heads = None\n",
        "\n",
        "        if task_type in ['classification', 'both']:\n",
        "            self.cls_heads = nn.ModuleList([\n",
        "                nn.Linear(feat_dim, 1) for _ in range(num_tasks)\n",
        "            ])\n",
        "            self.bce = nn.BCEWithLogitsLoss()\n",
        "            if loss_type == 'class_balanced':\n",
        "                self.register_buffer(\"class_weights\", torch.ones(num_tasks))\n",
        "        else:\n",
        "            self.cls_heads = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        out = {}\n",
        "\n",
        "        if self.task_type in ['regression', 'both']:\n",
        "            reg_outs = [head(f).squeeze(1) * 10 for head in self.reg_heads]  # [0, 10]\n",
        "            out['regression'] = torch.stack(reg_outs, dim=1)\n",
        "\n",
        "        if self.task_type in ['classification', 'both']:\n",
        "            cls_outs = [head(f).squeeze(1) for head in self.cls_heads]\n",
        "            out['classification'] = torch.stack(cls_outs, dim=1)  # logits\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _compute_loss(self, preds, targets):\n",
        "        reg_loss = torch.tensor(0.0, device=self.device)\n",
        "        cls_loss = torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        if self.task_type in ['regression', 'both']:\n",
        "            reg_loss = self.mse(preds['regression'], targets)\n",
        "\n",
        "        if self.task_type in ['classification', 'both']:\n",
        "            cls_targets = (targets > 0).float()\n",
        "            if self.loss_type == 'class_balanced':\n",
        "                weights = self.class_weights.unsqueeze(0)  # [1, num_tasks]\n",
        "                cls_loss = F.binary_cross_entropy_with_logits(preds['classification'], cls_targets, weight=weights)\n",
        "            else:\n",
        "                cls_loss = self.bce(preds['classification'], cls_targets)\n",
        "\n",
        "        if self.loss_weighting_strategy == 'gradnorm':\n",
        "            # Пример gradnorm: (для сложных задач можно заменить на свой)\n",
        "            try:\n",
        "                reg_grad = torch.autograd.grad(reg_loss, self.reg_heads.parameters(), retain_graph=True, allow_unused=True)\n",
        "                reg_norm = sum([g.norm() for g in reg_grad if g is not None]) + 1e-8\n",
        "            except:\n",
        "                reg_norm = torch.tensor(1.0, device=self.device)\n",
        "            try:\n",
        "                cls_grad = torch.autograd.grad(cls_loss, self.cls_heads.parameters(), retain_graph=True, allow_unused=True)\n",
        "                cls_norm = sum([g.norm() for g in cls_grad if g is not None]) + 1e-8\n",
        "            except:\n",
        "                cls_norm = torch.tensor(1.0, device=self.device)\n",
        "            total = reg_norm + cls_norm\n",
        "            loss = (reg_loss * cls_norm + cls_loss * reg_norm) / total\n",
        "        else:\n",
        "            loss = reg_loss + cls_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        preds = self(x)\n",
        "        loss = self._compute_loss(preds, y)\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        preds = self(x)\n",
        "        loss = self._compute_loss(preds, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "\n",
        "        # Cохраняем для метрик после эпохи\n",
        "        if not hasattr(self, 'val_outputs'):\n",
        "            self.val_outputs = []\n",
        "        # detach, чтобы не тащить граф\n",
        "        preds_detached = {k: v.detach().cpu() for k, v in preds.items()}\n",
        "        self.val_outputs.append({'preds': preds_detached, 'target': y.detach().cpu()})\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if not hasattr(self, 'val_outputs') or len(self.val_outputs) == 0:\n",
        "            return\n",
        "        preds_all = {k: self.val_outputs[0]['preds'][k] for k in self.val_outputs[0]['preds']}\n",
        "        for o in self.val_outputs[1:]:\n",
        "            for k in preds_all:\n",
        "                preds_all[k] = torch.cat([preds_all[k], o['preds'][k]], dim=0)\n",
        "        targets = torch.cat([o['target'] for o in self.val_outputs], dim=0)\n",
        "\n",
        "        if 'regression' in preds_all:\n",
        "            mae = torch.mean(torch.abs(preds_all['regression'] - targets))\n",
        "            self.log('val_mae', mae, prog_bar=True)\n",
        "\n",
        "        if 'classification' in preds_all:\n",
        "            preds_bin = (torch.sigmoid(preds_all['classification']) > 0.5).float()\n",
        "            true_bin = (targets > 0).float()\n",
        "            acc = (preds_bin == true_bin).float().mean()\n",
        "            self.log('val_cls_acc', acc, prog_bar=True)\n",
        "\n",
        "        self.val_outputs.clear()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "    def set_class_weights(self, y_bin):\n",
        "        \"\"\"Установить веса классов по бинарной матрице (0 или 1)\"\"\"\n",
        "        weights = []\n",
        "        for i in range(y_bin.shape[1]):\n",
        "            try:\n",
        "                w = compute_class_weight(class_weight='balanced', classes=[0,1], y=y_bin[:, i])\n",
        "                weights.append(torch.tensor(w[1], dtype=torch.float32))\n",
        "            except:\n",
        "                weights.append(torch.tensor(1.0))\n",
        "        self.class_weights = torch.stack(weights).to(self.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZidFXv0xzY7"
      },
      "source": [
        "Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0bf6d9b"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # метрика, которую отслеживаем\n",
        "    mode='min',            # минимизация ошибки\n",
        "    patience=3,            # сколько эпох ждать без улучшений\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/resnet50.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('resnet50', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/resnet50.ckpt')\n",
        "else:\n",
        "    print(\"✅ Модель уже обучена: models/resnet50.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7767d66e"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # метрика, которую отслеживаем\n",
        "    mode='min',            # минимизация ошибки\n",
        "    patience=3,            # сколько эпох ждать без улучшений\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/efficientnet_b3.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('tf_efficientnet_b3_ns', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/efficientnet_b3.ckpt')\n",
        "else:\n",
        "    print(\"✅ Модель уже обучена: models/efficientnet_b3.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c72a47c1"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # метрика, которую отслеживаем\n",
        "    mode='min',            # минимизация ошибки\n",
        "    patience=3,            # сколько эпох ждать без улучшений\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/vit_b16.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('vit_base_patch16_224', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/vit_b16.ckpt')\n",
        "else:\n",
        "    print(\"✅ Модель уже обучена: models/vit_b16.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5b395f2d"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # метрика, которую отслеживаем\n",
        "    mode='min',            # минимизация ошибки\n",
        "    patience=3,            # сколько эпох ждать без улучшений\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/clip_vit_b32.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('vit_base_patch16_clip_224.openai', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/clip_vit_b32.ckpt')\n",
        "else:\n",
        "    print(\"✅ Модель уже обучена: models/clip_vit_b32.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfVJbq5-1W3L"
      },
      "source": [
        "Ансамбль предсказаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T9LzeDq81Yd0"
      },
      "outputs": [],
      "source": [
        "# === 1. Пути к чекпойнтам моделей ===\n",
        "ckpts = {\n",
        "    'vitb16':    'models/vit_b16.ckpt',\n",
        "    'efnb3':     'models/efficientnet_b3.ckpt',\n",
        "    'resnet50':  'models/resnet50.ckpt'\n",
        "}\n",
        "\n",
        "# === 2. Проверка наличия всех моделей ===\n",
        "if all(os.path.exists(path) for path in ckpts.values()):\n",
        "    print(\"✅ Все модели для ансамбля найдены. Загружаем...\")\n",
        "\n",
        "    # Загрузка моделей\n",
        "    models = {\n",
        "        name: CompositionLitModel.load_from_checkpoint(path).eval().to(device)\n",
        "        for name, path in ckpts.items()\n",
        "    }\n",
        "\n",
        "    # === 3. Инференс ансамбля ===\n",
        "    @torch.no_grad()\n",
        "    def ensemble_predict(dl):\n",
        "        all_preds, all_targets = [], []\n",
        "        for x, y in dl:\n",
        "            x = x.to(device)\n",
        "            preds_list = [model(x)['regression'] for model in models.values()]\n",
        "            ensemble = torch.stack(preds_list).mean(dim=0)\n",
        "            all_preds.append(ensemble.cpu())\n",
        "            all_targets.append(y)\n",
        "        return torch.cat(all_preds), torch.cat(all_targets)\n",
        "\n",
        "    # Получение данных\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    dm.setup()\n",
        "    val_dl = dm.val_dataloader()\n",
        "    ens_preds, targets = ensemble_predict(val_dl)\n",
        "\n",
        "    # === 4. Метрики ===\n",
        "    mae_mean = mean_absolute_error(targets.numpy(), ens_preds.numpy())\n",
        "    mae_per_rule = torch.mean(torch.abs(ens_preds - targets), dim=0).numpy()\n",
        "\n",
        "    print(f\"📊 MAE ансамбля (среднее): {mae_mean:.4f}\")\n",
        "    for i, mae in enumerate(mae_per_rule):\n",
        "        print(f\"Rule {i+1:02d}: MAE = {mae:.4f}\")\n",
        "\n",
        "    # === 5. Добавление в таблицу метрик ===\n",
        "    if \"metrics_df\" not in locals():\n",
        "        metrics_df = pd.DataFrame(columns=[\"model\", \"val_mae\", \"val_cls_acc\"])\n",
        "    metrics_df.loc[len(metrics_df)] = ['ensemble_vit_effnet_resnet', mae_mean, np.nan]\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ Не все модели найдены. Пропуск ансамбля:\")\n",
        "    for name, path in ckpts.items():\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"  ⛔ отсутствует: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHXd_Uhm1buN"
      },
      "source": [
        "SVM на фичах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzQJLZ771dd4"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "SVR_MODEL_DIR = 'models/svr_vitb16'\n",
        "os.makedirs(SVR_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# === 1. Извлечение фичей из ViT-B/16 ===\n",
        "feature_extractor = models['vitb16'].backbone\n",
        "feature_extractor.eval().to(device)\n",
        "\n",
        "X_train, Y_train = [], []\n",
        "for x, y in dm.train_dataloader():\n",
        "    with torch.no_grad():\n",
        "        feats = feature_extractor(x.to(device))\n",
        "    X_train.append(feats.cpu().numpy())\n",
        "    Y_train.append(y.numpy())\n",
        "\n",
        "X_train = np.vstack(X_train)\n",
        "Y_train = np.vstack(Y_train)\n",
        "\n",
        "# === 2. Обучение или загрузка моделей SVR ===\n",
        "svm_models = []\n",
        "retrained = False\n",
        "\n",
        "if TRAIN_MODELS and not all(os.path.exists(f'{SVR_MODEL_DIR}/rule_{i+1:02d}.joblib') for i in range(13)):\n",
        "    print(\"🚀 Обучение моделей SVR...\")\n",
        "\n",
        "    for i in range(13):\n",
        "        # Разделим на подвалидацию для упрощённого варианта \"early stopping\"\n",
        "        X_subtrain, X_subval, y_subtrain, y_subval = train_test_split(\n",
        "            X_train, Y_train[:, i], test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        best_mae = float('inf')\n",
        "        best_model = None\n",
        "\n",
        "        for c_val in [0.1, 1.0, 10.0]:  # аналог подбора по метрике\n",
        "            model = SVR(kernel='rbf', C=c_val, epsilon=0.1)\n",
        "            model.fit(X_subtrain, y_subtrain)\n",
        "            pred_val = model.predict(X_subval)\n",
        "            mae = mean_absolute_error(y_subval, pred_val)\n",
        "            if mae < best_mae:\n",
        "                best_mae = mae\n",
        "                best_model = model\n",
        "\n",
        "        joblib.dump(best_model, f'{SVR_MODEL_DIR}/rule_{i+1:02d}.joblib')\n",
        "        svm_models.append(best_model)\n",
        "        print(f\"Rule {i+1:02d} — best C={best_model.C}, val MAE={best_mae:.4f}\")\n",
        "\n",
        "    retrained = True\n",
        "else:\n",
        "    print(\"✅ Модели SVR уже обучены. Загрузка из файлов...\")\n",
        "    for i in range(13):\n",
        "        model = joblib.load(f'{SVR_MODEL_DIR}/rule_{i+1:02d}.joblib')\n",
        "        svm_models.append(model)\n",
        "\n",
        "# === 3. Предсказания на валидации ===\n",
        "X_val, Y_val = [], []\n",
        "for x, y in dm.val_dataloader():\n",
        "    with torch.no_grad():\n",
        "        feats = feature_extractor(x.to(device))\n",
        "    X_val.append(feats.cpu().numpy())\n",
        "    Y_val.append(y.numpy())\n",
        "\n",
        "X_val = np.vstack(X_val)\n",
        "Y_val = np.vstack(Y_val)\n",
        "\n",
        "# === 4. Предсказания и метрики ===\n",
        "preds_val = np.stack([svm.predict(X_val) for svm in svm_models], axis=1)\n",
        "mae_svm = mean_absolute_error(Y_val, preds_val)\n",
        "mae_per_rule = np.mean(np.abs(preds_val - Y_val), axis=0)\n",
        "\n",
        "print(f\"📊 SVR (ViT) MAE (среднее): {mae_svm:.4f}\")\n",
        "for i, mae in enumerate(mae_per_rule):\n",
        "    print(f\"Rule {i+1:02d}: MAE = {mae:.4f}\")\n",
        "\n",
        "# === 5. Добавление в общую таблицу метрик ===\n",
        "if \"metrics_df\" not in locals():\n",
        "    metrics_df = pd.DataFrame(columns=[\"model\", \"val_mae\", \"val_cls_acc\"])\n",
        "\n",
        "metrics_df.loc[len(metrics_df)] = ['svm_vitb16_features', mae_svm, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vx-gwyw6F73"
      },
      "source": [
        "Унификация предсказаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8b4c2874"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_model(model, dataloader, device='cuda'):\n",
        "    preds_reg, preds_cls, targets = [], [], []\n",
        "    is_torch_model = isinstance(model, torch.nn.Module)\n",
        "    if is_torch_model:\n",
        "        model.eval().to(device)\n",
        "    for x, y in dataloader:\n",
        "        if is_torch_model:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "        out = model(x)\n",
        "        targets.append(y.cpu() if is_torch_model else y)\n",
        "        if 'regression' in out:\n",
        "            preds_reg.append(out['regression'].detach().cpu() if is_torch_model else out['regression'])\n",
        "        if 'classification' in out:\n",
        "            preds_cls.append(torch.sigmoid(out['classification'].detach().cpu()) if is_torch_model else out['classification'])\n",
        "    result = {}\n",
        "    if preds_reg:\n",
        "        result['regression'] = torch.cat(preds_reg, dim=0)\n",
        "    if preds_cls:\n",
        "        result['classification'] = torch.cat(preds_cls, dim=0)\n",
        "    result['target'] = torch.cat(targets, dim=0)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxAyfYnX1iHW"
      },
      "source": [
        "Сбор и логирование метрик"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lHGpScYD4Yjl"
      },
      "outputs": [],
      "source": [
        "class SVMWrapper:\n",
        "    def __init__(self, models, feature_extractor, device='cuda'):\n",
        "        self.models = models\n",
        "        self.feature_extractor = feature_extractor.eval().to(device)\n",
        "        self.device = device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, x):\n",
        "        feats = self.feature_extractor(x.to(self.device)).cpu().numpy()\n",
        "        preds = np.stack([m.predict(feats) for m in self.models], axis=1)\n",
        "        return {'regression': torch.tensor(preds, dtype=torch.float32)}\n",
        "\n",
        "class EnsembleWrapper:\n",
        "    def __init__(self, models_dict, device='cuda'):\n",
        "        self.models = {k: m.eval().to(device) for k, m in models_dict.items()}\n",
        "        self.device = device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, x):\n",
        "        x = x.to(self.device)\n",
        "        preds = [m(x)['regression'] for m in self.models.values()]\n",
        "        mean_preds = torch.stack(preds).mean(dim=0)\n",
        "        return {'regression': mean_preds}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d38a53e"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_model(name, model, dataloader):\n",
        "    # Приведение модели в eval и перенос на устройство — только для torch-моделей\n",
        "    if isinstance(model, torch.nn.Module):\n",
        "        model.eval().to(device)\n",
        "\n",
        "    all_targets, all_reg_preds, all_cls_preds = [], [], []\n",
        "\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        all_targets.append(y.cpu())\n",
        "\n",
        "        if 'regression' in output:\n",
        "            all_reg_preds.append(output['regression'].cpu())\n",
        "        if 'classification' in output:\n",
        "            all_cls_preds.append(output['classification'].cpu())\n",
        "\n",
        "    scores = {'model': name}\n",
        "    y_true = torch.cat(all_targets).numpy()\n",
        "\n",
        "    # MAE + RMSE\n",
        "    if all_reg_preds:\n",
        "        y_pred = torch.cat(all_reg_preds).numpy()\n",
        "        scores['MAE'] = mean_absolute_error(y_true, y_pred)\n",
        "        scores['RMSE'] = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    # Accuracy (предпочтительно по classification, иначе по threshold от regression)\n",
        "    if all_cls_preds:\n",
        "        y_pred_cls = torch.cat(all_cls_preds).numpy() > 0.5\n",
        "        y_true_cls = y_true > 0\n",
        "        scores['Accuracy'] = accuracy_score(y_true_cls.flatten(), y_pred_cls.flatten())\n",
        "    elif all_reg_preds:\n",
        "        y_pred_cls = y_pred > 0\n",
        "        y_true_cls = y_true > 0\n",
        "        scores['Accuracy'] = accuracy_score(y_true_cls.flatten(), y_pred_cls.flatten())\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def benchmark_all(models_dict, dataloader):\n",
        "    metrics = []\n",
        "\n",
        "    for name, model in models_dict.items():\n",
        "        print(f\"🔍 Оценка модели: {name}\")\n",
        "\n",
        "        # Засекаем время только на инференс\n",
        "        start = time.time()\n",
        "        scores = evaluate_model(name, model, dataloader)\n",
        "        duration = time.time() - start\n",
        "\n",
        "        # Подсчёт latency (если доступен размер датасета)\n",
        "        try:\n",
        "            num_samples = len(dataloader.dataset)\n",
        "            scores['Latency (ms/img)'] = 1000 * duration / num_samples\n",
        "        except Exception as e:\n",
        "            scores['Latency (ms/img)'] = None\n",
        "            print(f\"⚠️ Не удалось рассчитать latency: {e}\")\n",
        "\n",
        "        metrics.append(scores)\n",
        "\n",
        "        # Отладочный вывод\n",
        "        print(f\"✅ {name}: MAE={scores.get('MAE', '—')}, Accuracy={scores.get('Accuracy', '—')}, Latency={scores['Latency (ms/img)']:.2f} ms\")\n",
        "\n",
        "    return pd.DataFrame(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAeGvZyh67cW"
      },
      "source": [
        "AutoModelSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "360234fa"
      },
      "outputs": [],
      "source": [
        "def normalize_column(df, column, inverse=False):\n",
        "    col = df[column].copy()\n",
        "    if col.isnull().all():\n",
        "        return pd.Series([0.0] * len(df))\n",
        "    col = (col - col.min()) / (col.max() - col.min() + 1e-8)\n",
        "    return 1.0 - col if inverse else col\n",
        "\n",
        "def compute_total_score(df, weights={'MAE': 0.5, 'Accuracy': 0.4, 'Latency': 0.1}):\n",
        "    norm_mae = normalize_column(df, 'MAE', inverse=True)\n",
        "    norm_acc = normalize_column(df, 'Accuracy')\n",
        "    norm_latency = normalize_column(df, 'Latency (ms/img)', inverse=True)\n",
        "\n",
        "    total = (\n",
        "        weights['MAE'] * norm_mae +\n",
        "        weights['Accuracy'] * norm_acc +\n",
        "        weights['Latency'] * norm_latency\n",
        "    )\n",
        "    return total\n",
        "\n",
        "def select_best_model(df: pd.DataFrame):\n",
        "    df_copy = df.copy()\n",
        "    df_copy['total_score'] = compute_total_score(df_copy)\n",
        "    df_sorted = df_copy.sort_values(by='total_score', ascending=False)\n",
        "    best_model_row = df_sorted.iloc[0]\n",
        "    return df_sorted, best_model_row\n",
        "\n",
        "\n",
        "# === Инициализация моделей ===\n",
        "model_dict = {\n",
        "    'ResNet50': CompositionLitModel.load_from_checkpoint('models/resnet50.ckpt'),\n",
        "    'EffNet-B3': CompositionLitModel.load_from_checkpoint('models/efficientnet_b3.ckpt'),\n",
        "    'ViT-B/16': CompositionLitModel.load_from_checkpoint('models/vit_b16.ckpt'),\n",
        "    'CLIP ViT-B/32': CompositionLitModel.load_from_checkpoint('models/clip_vit_b32.ckpt'),\n",
        "}\n",
        "for m in model_dict.values():\n",
        "    m.to(device)\n",
        "\n",
        "# SVM\n",
        "svm_model = SVMWrapper(svm_models, feature_extractor=models['vitb16'].backbone, device=device)\n",
        "model_dict['SVM (ViT features)'] = svm_model\n",
        "\n",
        "# Ensemble\n",
        "ensemble_model = EnsembleWrapper({\n",
        "    'resnet50': model_dict['ResNet50'],\n",
        "    'efnb3': model_dict['EffNet-B3'],\n",
        "    'vitb16': model_dict['ViT-B/16'],\n",
        "})\n",
        "model_dict['Ensemble (ResNet+EffNet+ViT)'] = ensemble_model\n",
        "\n",
        "# === Оценка ===\n",
        "df_metrics = benchmark_all(model_dict, dm.val_dataloader())\n",
        "df_metrics.to_csv('results/model_comparison.csv', index=False)\n",
        "\n",
        "# === Рейтинг и выбор лучшей ===\n",
        "df_ranked, best_model_row = select_best_model(df_metrics)\n",
        "df_ranked.to_csv('results/ranked_models.csv', index=False)\n",
        "\n",
        "# === Вывод ===\n",
        "print(\"🥇 Best model overall:\")\n",
        "display(best_model_row.to_frame().T)\n",
        "BEST_MODEL_NAME = best_model_row['model']\n",
        "BEST_MODEL = model_dict[BEST_MODEL_NAME]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e634505"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    \"\"\"Заменяет недопустимые символы для имени файла.\"\"\"\n",
        "    return re.sub(r'[^a-zA-Z0-9_.-]', '_', name)\n",
        "\n",
        "def save_best_model(model, name: str, save_dir: str = \"models\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    safe_name = sanitize_filename(name)\n",
        "\n",
        "    path_ckpt = os.path.join(save_dir, f\"best_model_{safe_name}.ckpt\")\n",
        "    path_pt = os.path.join(save_dir, f\"best_model_{safe_name}.pt\")\n",
        "    path_full = os.path.join(save_dir, f\"best_model_{safe_name}_full.pt\")\n",
        "\n",
        "    if isinstance(model, pl.LightningModule):\n",
        "        model = model.cpu().eval()\n",
        "        try:\n",
        "            model.save_checkpoint(path_ckpt)\n",
        "            print(f\"💾 Сохранено как Lightning checkpoint: {path_ckpt}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Ошибка при сохранении .ckpt: {e}\")\n",
        "\n",
        "        try:\n",
        "            torch.save(model.state_dict(), path_pt)\n",
        "            print(f\"💾 Сохранено только state_dict: {path_pt}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Ошибка при сохранении state_dict: {e}\")\n",
        "\n",
        "        try:\n",
        "            torch.save(model, path_full)\n",
        "            print(f\"💾 Сохранено как полная модель: {path_full}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Ошибка при сохранении полной модели: {e}\")\n",
        "\n",
        "    elif isinstance(model, SVMWrapper):\n",
        "        path_svm = os.path.join(save_dir, f\"{safe_name}_svm.joblib\")\n",
        "        try:\n",
        "            joblib.dump(model, path_svm)\n",
        "            print(f\"💾 Сохранён SVMWrapper: {path_svm}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Ошибка при сохранении SVMWrapper: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Неизвестный тип модели: {type(model)}. Пропуск сохранения.\")\n",
        "\n",
        "# === Вызов ===\n",
        "save_best_model(BEST_MODEL, BEST_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4cbbf06"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_reliability(y_true, y_prob, title='Reliability Diagram'):\n",
        "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Оценим калибровку по всем правилам\n",
        "res = predict_model(BEST_MODEL, dm.test_dataloader(), device=device)\n",
        "if 'classification' in res:\n",
        "    y_true_bin = (res['target'] > 0).numpy()\n",
        "    y_pred_prob = res['classification'].numpy()\n",
        "\n",
        "    for i in range(min(5, y_true_bin.shape[1])):  # Покажем первые 5 правил\n",
        "        plot_reliability(y_true_bin[:, i], y_pred_prob[:, i], title=f'Rule {i+1} calibration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "607611c0"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Отчёт: графики по всем метрикам\n",
        "def plot_metric(df, metric_name, title=None, save_path=None):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(x='model', y=metric_name, data=df, palette='viridis')\n",
        "    plt.title(title or metric_name)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "plot_metric(df_ranked, 'MAE', 'Средняя абсолютная ошибка (MAE)', 'results/plot_mae.png')\n",
        "plot_metric(df_ranked, 'RMSE', 'Среднеквадратичная ошибка (RMSE)', 'results/plot_rmse.png')\n",
        "if 'Accuracy' in df_ranked.columns:\n",
        "    plot_metric(df_ranked, 'Accuracy', 'Точность классификации (Accuracy)', 'results/plot_accuracy.png')\n",
        "plot_metric(df_ranked, 'Latency (ms/img)', 'Скорость инференса', 'results/plot_latency.png')\n",
        "plot_metric(df_ranked, 'total_score', 'Итоговый рейтинг моделей', 'results/plot_score.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b57de982"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def generate_comparative_report(df):\n",
        "    summary = []\n",
        "\n",
        "    best_mae = df.sort_values('MAE').iloc[0]\n",
        "    best_rmse = df.sort_values('RMSE').iloc[0]\n",
        "    best_acc = df.sort_values('Accuracy', ascending=False).iloc[0] if 'Accuracy' in df.columns else None\n",
        "    best_latency = df.sort_values('Latency (ms/img)').iloc[0]\n",
        "    best_total = df.sort_values('total_score', ascending=False).iloc[0]\n",
        "\n",
        "    summary.append(f\"**Лучшая модель по MAE:** {best_mae['model']} ({best_mae['MAE']:.4f})\")\n",
        "    summary.append(f\"**Лучшая модель по RMSE:** {best_rmse['model']} ({best_rmse['RMSE']:.4f})\")\n",
        "    if best_acc is not None:\n",
        "        summary.append(f\"**Лучшая модель по Accuracy:** {best_acc['model']} ({best_acc['Accuracy']:.4f})\")\n",
        "    summary.append(f\"**Самая быстрая модель:** {best_latency['model']} ({best_latency['Latency (ms/img)']:.2f} ms/img)\")\n",
        "    summary.append(f\"**Лучшая модель по совокупной оценке:** {best_total['model']} (score: {best_total['total_score']:.4f})\")\n",
        "\n",
        "    display(Markdown(\"### 📊 Сводный сравнительный отчёт\"))\n",
        "    for line in summary:\n",
        "        display(Markdown(\"- \" + line))\n",
        "\n",
        "generate_comparative_report(df_ranked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TXOQ5uVUIHW"
      },
      "source": [
        "Интерпретация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOl6MMTO6HhE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class RegressionChannelWrapper(nn.Module):\n",
        "    def __init__(self, model, channel_index=0):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.channel_index = channel_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out['regression'][:, self.channel_index].unsqueeze(1)\n",
        "\n",
        "def get_last_conv_layer(model):\n",
        "    if hasattr(model, 'layer4'):\n",
        "        return model.layer4[-1], False\n",
        "    elif hasattr(model, 'blocks'):\n",
        "        return model.blocks[-1], True\n",
        "    elif hasattr(model, 'conv_head'):\n",
        "        return model.conv_head, False\n",
        "    else:\n",
        "        raise ValueError(\"Не удалось определить последний conv-слой.\")\n",
        "\n",
        "def reshape_transform_vit(tensor, height=14, width=14):\n",
        "    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, tensor.size(2))\n",
        "    return result.permute(0, 3, 1, 2)\n",
        "\n",
        "# --- Конфигурация\n",
        "rule_index = 0  # \"center\"\n",
        "wrapped_model = RegressionChannelWrapper(BEST_MODEL, channel_index=rule_index).to(device)\n",
        "target_layer, use_vit = get_last_conv_layer(BEST_MODEL.backbone)\n",
        "reshape_transform = reshape_transform_vit if use_vit else None\n",
        "\n",
        "cam = GradCAM(model=wrapped_model,\n",
        "              target_layers=[target_layer],\n",
        "              reshape_transform=reshape_transform)\n",
        "\n",
        "best_score = -1\n",
        "best_img_rgb = None\n",
        "best_heatmap = None\n",
        "\n",
        "# --- Проход по датасету\n",
        "for imgs, ys in dm.val_dataloader():\n",
        "    for i in range(imgs.size(0)):\n",
        "        img = imgs[i].unsqueeze(0).to(device)\n",
        "        rgb = imgs[i].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        grayscale = cam(input_tensor=img)[0]\n",
        "\n",
        "        # Оценка: сколько \"внимания\" в центре\n",
        "        h, w = grayscale.shape\n",
        "        ch, cw = h // 3, w // 3\n",
        "        center_mask = np.zeros_like(grayscale)\n",
        "        center_mask[h//3:2*h//3, w//3:2*w//3] = 1\n",
        "        center_score = (grayscale * center_mask).sum() / grayscale.sum()\n",
        "\n",
        "        if center_score > best_score:\n",
        "            best_score = center_score\n",
        "            best_img_rgb = rgb\n",
        "            best_heatmap = show_cam_on_image(rgb, grayscale, use_rgb=True)\n",
        "\n",
        "    # ограничим одним батчем, если долго:\n",
        "    break\n",
        "\n",
        "# --- Сохранение лучшего примера\n",
        "plt.imshow(best_heatmap)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Grad-CAM: центр внимания в центре (score={best_score:.2f})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f18c128b"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# Обёртка для модели с выбором одного регрессионного канала\n",
        "class RegressionChannelWrapper(nn.Module):\n",
        "    def __init__(self, model, channel_index=0):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.channel_index = channel_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out['regression'][:, self.channel_index].unsqueeze(1)\n",
        "\n",
        "# Определение последнего слоя + является ли ViT\n",
        "def get_last_conv_layer(model):\n",
        "    if hasattr(model, 'layer4'):\n",
        "        return model.layer4[-1], False  # ResNet\n",
        "    elif hasattr(model, 'blocks'):\n",
        "        return model.blocks[-1], True   # ViT / CLIP\n",
        "    elif hasattr(model, 'conv_head'):\n",
        "        return model.conv_head, False   # EfficientNet\n",
        "    else:\n",
        "        raise ValueError(\"Не удалось определить последний conv-слой модели.\")\n",
        "\n",
        "# Преобразование для ViT: [B, N, C] → [B, C, H, W]\n",
        "def reshape_transform_vit(tensor, height=14, width=14):\n",
        "    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, tensor.size(2))\n",
        "    result = result.permute(0, 3, 1, 2)  # [B, C, H, W]\n",
        "    return result\n",
        "\n",
        "# Признак 0 (например, \"center\")\n",
        "rule_index = 0\n",
        "wrapped_model = RegressionChannelWrapper(BEST_MODEL, channel_index=rule_index).to(device)\n",
        "target_layer, use_vit = get_last_conv_layer(BEST_MODEL.backbone)\n",
        "reshape_transform = reshape_transform_vit if use_vit else None\n",
        "\n",
        "cam = GradCAM(\n",
        "    model=wrapped_model,\n",
        "    target_layers=[target_layer],\n",
        "    reshape_transform=reshape_transform\n",
        ")\n",
        "\n",
        "imgs, ys = next(iter(dm.val_dataloader()))\n",
        "img = imgs[0].unsqueeze(0).to(device)\n",
        "rgb = imgs[0].permute(1, 2, 0).numpy()\n",
        "\n",
        "grayscale = cam(input_tensor=img)[0]\n",
        "heatmap = show_cam_on_image(rgb, grayscale, use_rgb=True)\n",
        "\n",
        "plt.imshow(heatmap)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Grad-CAM | Признак {rule_index + 1}\")\n",
        "plt.savefig(\"results/gradcam_vit.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4favj5r1mp9"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import torch.nn as nn\n",
        "\n",
        "# Обёртка для вывода одного признака\n",
        "class SHAPWrapper(nn.Module):\n",
        "    def __init__(self, model, channel_index=0):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.channel_index = channel_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out['regression'][:, self.channel_index].unsqueeze(1)\n",
        "\n",
        "# Настройка\n",
        "rule_index = 0  # например, центр\n",
        "shap_model = SHAPWrapper(BEST_MODEL, channel_index=rule_index).to(device)\n",
        "\n",
        "# Данные\n",
        "background = next(iter(dm.train_dataloader()))[0][:16].to(device)\n",
        "test_imgs, _ = next(iter(dm.val_dataloader()))\n",
        "test_imgs = test_imgs[:5].to(device)\n",
        "\n",
        "# SHAP (градиентный)\n",
        "e = shap.GradientExplainer(shap_model, background)\n",
        "shap_vals = e.shap_values(test_imgs)\n",
        "\n",
        "# Приведение к [B, H, W, C]\n",
        "test_imgs_nhwc = test_imgs.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "# Исправляем: (5, 3, 224, 224, 1) → (5, 224, 224, 3)\n",
        "shap_vals_correct = shap_vals.transpose(0, 2, 3, 1, 4).squeeze(-1)\n",
        "\n",
        "# Визуализация\n",
        "shap.image_plot([shap_vals_correct], test_imgs_nhwc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d23daa0b"
      },
      "outputs": [],
      "source": [
        "# SHAP summary plot (SVM на ViT)\n",
        "import joblib\n",
        "svms = [joblib.load(f'models/svr_vitb16/rule_{i+1:02d}.joblib') for i in range(13)]\n",
        "feature_extractor = models['vitb16'].backbone.eval().to(device)\n",
        "\n",
        "X_val = []\n",
        "for x, y in dm.val_dataloader():\n",
        "    with torch.no_grad():\n",
        "        feats = feature_extractor(x.to(device)).cpu().numpy()\n",
        "    X_val.append(feats)\n",
        "X_val = np.vstack(X_val)\n",
        "\n",
        "explainer = shap.Explainer(svms[0].predict, X_val)\n",
        "shap_vals = explainer(X_val[:100])\n",
        "\n",
        "shap.summary_plot(shap_vals.values, X_val[:100], feature_names=[f\"f{i+1}\" for i in range(X_val.shape[1])], show=False)\n",
        "plt.savefig('results/shap_summary.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2t7_N-p7HuA"
      },
      "outputs": [],
      "source": [
        "ranking.plot(x='model', y='score', kind='bar', legend=False)\n",
        "plt.title('Сводный рейтинг моделей')\n",
        "plt.ylabel('Score')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}