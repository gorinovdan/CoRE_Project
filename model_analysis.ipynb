{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fscrZhs0d9w"
      },
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrZ_L0Br0Z3q",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# PyTorch, Lightning, timm, torchvision, shap, grad-cam, scikit-learn, pandas, matplotlib\n",
        "!pip install torch torchvision timm pytorch-lightning pytorch-gradcam shap scikit-learn pandas matplotlib grad-cam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KQ9r9gf0hER"
      },
      "source": [
        "–ò–º–ø–æ—Ä—Ç—ã –∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSuq8LGF0jDL"
      },
      "outputs": [],
      "source": [
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import pytorch_lightning as pl\n",
        "import timm\n",
        "from sklearn.svm import SVR\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
        "\n",
        "# –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVrXcoP90sJw"
      },
      "source": [
        "–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrWscCnC45Wc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Diplom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "472ec4c9"
      },
      "outputs": [],
      "source": [
        "# === –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –ø—É—Ç—å –∫ CSV –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º===\n",
        "# –§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'new_filename' –∏ 13 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–æ—Ç 0.0 –¥–æ 10.0)\n",
        "CSV_PATH = 'CoRE_Dataset/unified_dataset.csv'\n",
        "IMG_DIR = 'CoRE_Dataset/images/'\n",
        "\n",
        "# === –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã ===\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224\n",
        "LR = 1e-4\n",
        "MAX_EPOCHS = 30\n",
        "\n",
        "# === –û–ø—Ü–∏–∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ===\n",
        "loss_type = \"class_balanced\"            # –∏–ª–∏ \"mse\"\n",
        "loss_weighting_strategy = \"gradnorm\"    # –∏–ª–∏ None\n",
        "use_class_aware_augmentation = True\n",
        "use_class_aware_sampler = True\n",
        "use_oversampling = True\n",
        "oversample_factor = 2.0\n",
        "rare_class_threshold = 0.05\n",
        "\n",
        "print(f'üîÑ CSV –ø—É—Ç—å: {CSV_PATH}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7752698"
      },
      "outputs": [],
      "source": [
        "# === –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===\n",
        "TRAIN_MODELS = True\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umJhaoi50zvV"
      },
      "source": [
        "DataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8s5SPIc0yye"
      },
      "outputs": [],
      "source": [
        "class CompositionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∏—Ö 13 –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫.\n",
        "    –û–∂–∏–¥–∞–µ—Ç—Å—è DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: 'new_filename' + 13 float-–æ—Ü–µ–Ω–æ–∫.\n",
        "    \"\"\"\n",
        "    def __init__(self, df: pd.DataFrame, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_paths = df['new_filename'].values\n",
        "        self.targets = df.iloc[:, 1:].astype(np.float32).values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except (FileNotFoundError, OSError) as e:\n",
        "            print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª: {img_path} ‚Äî {e}\")\n",
        "            # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Å–±–æ—è\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(self.targets[idx])\n",
        "\n",
        "\n",
        "class CompositionDataModule(pl.LightningDataModule):\n",
        "    \"\"\"\n",
        "    PyTorch Lightning DataModule –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ train/val/test —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:\n",
        "    - class-aware –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
        "    - class-aware sampler\n",
        "    - oversampling –ø–æ —Ä–µ–¥–∫–∏–º –ø—Ä–∞–≤–∏–ª–∞–º\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_path: str, img_size: int, batch_size: int):\n",
        "        super().__init__()\n",
        "        self.csv_path = csv_path\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        df['new_filename'] = df['new_filename'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
        "\n",
        "        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 'new_filename' + 13 –æ—Ü–µ–Ω–æ–∫\n",
        "        rule_columns = [\n",
        "            \"center\", \"curved\", \"diagonal\", \"fill_the_frame\", \"pattern\",\n",
        "            \"rule_of_thirds\", \"symmetric\", \"triangle\", \"vanishing_point\",\n",
        "            \"golden_ratio\", \"horizontal\", \"radial\", \"vertical\"\n",
        "        ]\n",
        "        df = df[[\"new_filename\"] + rule_columns]\n",
        "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å 13 –ø—Ä–∞–≤–∏–ª–∞–º–∏ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏.\")\n",
        "\n",
        "        # –¢—Ä–∏ —Ä–∞–∑–¥–µ–ª–∞: train/val/test (60/20/20)\n",
        "        df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "        N = len(df)\n",
        "        n_train = int(0.6 * N)\n",
        "        n_val = int(0.2 * N)\n",
        "        self.df_train = df[:n_train]\n",
        "        self.df_val = df[n_train:n_train + n_val]\n",
        "        self.df_test = df[n_train + n_val:]\n",
        "        print(f\"üìä Split: train={len(self.df_train)}, val={len(self.df_val)}, test={len(self.df_test)}\")\n",
        "\n",
        "        # Transforms\n",
        "        train_tf = [T.RandomResizedCrop(self.img_size)]\n",
        "        if use_class_aware_augmentation:\n",
        "            train_tf += [T.ColorJitter(0.4, 0.4, 0.4, 0.1)]\n",
        "        train_tf += [T.RandomHorizontalFlip(), T.ToTensor()]\n",
        "        self.tf_train = T.Compose(train_tf)\n",
        "        self.tf_val = T.Compose([\n",
        "            T.Resize(self.img_size),\n",
        "            T.CenterCrop(self.img_size),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.ds_train = CompositionDataset(self.df_train, transform=self.tf_train)\n",
        "        self.ds_val   = CompositionDataset(self.df_val, transform=self.tf_val)\n",
        "        self.ds_test  = CompositionDataset(self.df_test, transform=self.tf_val)\n",
        "\n",
        "        # Class-aware oversampling –ø–æ —Ä–µ–¥–∫–∏–º –ø—Ä–∞–≤–∏–ª–∞–º\n",
        "        if use_oversampling:\n",
        "            binary_labels = (self.df_train.iloc[:, 1:] > 0).astype(int)\n",
        "            freq = binary_labels.mean()\n",
        "            rare = freq < rare_class_threshold\n",
        "            weights = []\n",
        "            for row in binary_labels.values:\n",
        "                w = 1.0\n",
        "                if any(row[rare.values]):\n",
        "                    w *= oversample_factor\n",
        "                weights.append(w)\n",
        "            self.train_sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "            print(f\"üîÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è oversampling —Å rare_class_threshold={rare_class_threshold}\")\n",
        "        else:\n",
        "            self.train_sampler = None\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.ds_train, batch_size=self.batch_size,\n",
        "                          shuffle=self.train_sampler is None,\n",
        "                          sampler=self.train_sampler, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.ds_val, batch_size=self.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.ds_test, batch_size=self.batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzwk2OWG05St"
      },
      "source": [
        "–û–±—â–∏–π LightningModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a564443"
      },
      "outputs": [],
      "source": [
        "class CompositionLitModel(pl.LightningModule):\n",
        "    def __init__(self, backbone_name, lr, num_tasks=13, task_type='regression',\n",
        "                 loss_type='default', loss_weighting_strategy=None):\n",
        "        \"\"\"\n",
        "        task_type: 'regression', 'classification', 'both'\n",
        "        loss_type: 'default' or 'class_balanced'\n",
        "        loss_weighting_strategy: None or 'gradnorm'\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.task_type = task_type\n",
        "        self.lr = lr\n",
        "        self.loss_type = loss_type\n",
        "        self.loss_weighting_strategy = loss_weighting_strategy\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Backbone\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0, global_pool='avg')\n",
        "        feat_dim = self.backbone.num_features\n",
        "\n",
        "        # Heads\n",
        "        if task_type in ['regression', 'both']:\n",
        "            # –í—ã—Ö–æ–¥ —Å —Å–∏–≥–º–æ–∏–¥–æ–π: –≤—Å–µ–≥–¥–∞ –≤ [0, 1] -> *10 => [0, 10]\n",
        "            self.reg_heads = nn.ModuleList([\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(feat_dim, 1),\n",
        "                    nn.Sigmoid()  # –°—Ç—Ä–æ–≥–æ [0, 1]\n",
        "                ) for _ in range(num_tasks)\n",
        "            ])\n",
        "            self.mse = nn.MSELoss()\n",
        "        else:\n",
        "            self.reg_heads = None\n",
        "\n",
        "        if task_type in ['classification', 'both']:\n",
        "            self.cls_heads = nn.ModuleList([\n",
        "                nn.Linear(feat_dim, 1) for _ in range(num_tasks)\n",
        "            ])\n",
        "            self.bce = nn.BCEWithLogitsLoss()\n",
        "            if loss_type == 'class_balanced':\n",
        "                self.register_buffer(\"class_weights\", torch.ones(num_tasks))\n",
        "        else:\n",
        "            self.cls_heads = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        out = {}\n",
        "\n",
        "        if self.task_type in ['regression', 'both']:\n",
        "            reg_outs = [head(f).squeeze(1) * 10 for head in self.reg_heads]  # [0, 10]\n",
        "            out['regression'] = torch.stack(reg_outs, dim=1)\n",
        "\n",
        "        if self.task_type in ['classification', 'both']:\n",
        "            cls_outs = [head(f).squeeze(1) for head in self.cls_heads]\n",
        "            out['classification'] = torch.stack(cls_outs, dim=1)  # logits\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _compute_loss(self, preds, targets):\n",
        "        reg_loss = torch.tensor(0.0, device=self.device)\n",
        "        cls_loss = torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        if self.task_type in ['regression', 'both']:\n",
        "            reg_loss = self.mse(preds['regression'], targets)\n",
        "\n",
        "        if self.task_type in ['classification', 'both']:\n",
        "            cls_targets = (targets > 0).float()\n",
        "            if self.loss_type == 'class_balanced':\n",
        "                weights = self.class_weights.unsqueeze(0)  # [1, num_tasks]\n",
        "                cls_loss = F.binary_cross_entropy_with_logits(preds['classification'], cls_targets, weight=weights)\n",
        "            else:\n",
        "                cls_loss = self.bce(preds['classification'], cls_targets)\n",
        "\n",
        "        if self.loss_weighting_strategy == 'gradnorm':\n",
        "            # –ü—Ä–∏–º–µ—Ä gradnorm: (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å–≤–æ–π)\n",
        "            try:\n",
        "                reg_grad = torch.autograd.grad(reg_loss, self.reg_heads.parameters(), retain_graph=True, allow_unused=True)\n",
        "                reg_norm = sum([g.norm() for g in reg_grad if g is not None]) + 1e-8\n",
        "            except:\n",
        "                reg_norm = torch.tensor(1.0, device=self.device)\n",
        "            try:\n",
        "                cls_grad = torch.autograd.grad(cls_loss, self.cls_heads.parameters(), retain_graph=True, allow_unused=True)\n",
        "                cls_norm = sum([g.norm() for g in cls_grad if g is not None]) + 1e-8\n",
        "            except:\n",
        "                cls_norm = torch.tensor(1.0, device=self.device)\n",
        "            total = reg_norm + cls_norm\n",
        "            loss = (reg_loss * cls_norm + cls_loss * reg_norm) / total\n",
        "        else:\n",
        "            loss = reg_loss + cls_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        preds = self(x)\n",
        "        loss = self._compute_loss(preds, y)\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        preds = self(x)\n",
        "        loss = self._compute_loss(preds, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "\n",
        "        # C–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –º–µ—Ç—Ä–∏–∫ –ø–æ—Å–ª–µ —ç–ø–æ—Ö–∏\n",
        "        if not hasattr(self, 'val_outputs'):\n",
        "            self.val_outputs = []\n",
        "        # detach, —á—Ç–æ–±—ã –Ω–µ —Ç–∞—â–∏—Ç—å –≥—Ä–∞—Ñ\n",
        "        preds_detached = {k: v.detach().cpu() for k, v in preds.items()}\n",
        "        self.val_outputs.append({'preds': preds_detached, 'target': y.detach().cpu()})\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if not hasattr(self, 'val_outputs') or len(self.val_outputs) == 0:\n",
        "            return\n",
        "        preds_all = {k: self.val_outputs[0]['preds'][k] for k in self.val_outputs[0]['preds']}\n",
        "        for o in self.val_outputs[1:]:\n",
        "            for k in preds_all:\n",
        "                preds_all[k] = torch.cat([preds_all[k], o['preds'][k]], dim=0)\n",
        "        targets = torch.cat([o['target'] for o in self.val_outputs], dim=0)\n",
        "\n",
        "        if 'regression' in preds_all:\n",
        "            mae = torch.mean(torch.abs(preds_all['regression'] - targets))\n",
        "            self.log('val_mae', mae, prog_bar=True)\n",
        "\n",
        "        if 'classification' in preds_all:\n",
        "            preds_bin = (torch.sigmoid(preds_all['classification']) > 0.5).float()\n",
        "            true_bin = (targets > 0).float()\n",
        "            acc = (preds_bin == true_bin).float().mean()\n",
        "            self.log('val_cls_acc', acc, prog_bar=True)\n",
        "\n",
        "        self.val_outputs.clear()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "    def set_class_weights(self, y_bin):\n",
        "        \"\"\"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –ø–æ –±–∏–Ω–∞—Ä–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ (0 –∏–ª–∏ 1)\"\"\"\n",
        "        weights = []\n",
        "        for i in range(y_bin.shape[1]):\n",
        "            try:\n",
        "                w = compute_class_weight(class_weight='balanced', classes=[0,1], y=y_bin[:, i])\n",
        "                weights.append(torch.tensor(w[1], dtype=torch.float32))\n",
        "            except:\n",
        "                weights.append(torch.tensor(1.0))\n",
        "        self.class_weights = torch.stack(weights).to(self.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZidFXv0xzY7"
      },
      "source": [
        "Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0bf6d9b"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # –º–µ—Ç—Ä–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º\n",
        "    mode='min',            # –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—à–∏–±–∫–∏\n",
        "    patience=3,            # —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö –∂–¥–∞—Ç—å –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/resnet50.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('resnet50', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/resnet50.ckpt')\n",
        "else:\n",
        "    print(\"‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞: models/resnet50.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7767d66e"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # –º–µ—Ç—Ä–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º\n",
        "    mode='min',            # –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—à–∏–±–∫–∏\n",
        "    patience=3,            # —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö –∂–¥–∞—Ç—å –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/efficientnet_b3.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('tf_efficientnet_b3_ns', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/efficientnet_b3.ckpt')\n",
        "else:\n",
        "    print(\"‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞: models/efficientnet_b3.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c72a47c1"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # –º–µ—Ç—Ä–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º\n",
        "    mode='min',            # –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—à–∏–±–∫–∏\n",
        "    patience=3,            # —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö –∂–¥–∞—Ç—å –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/vit_b16.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('vit_base_patch16_224', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/vit_b16.ckpt')\n",
        "else:\n",
        "    print(\"‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞: models/vit_b16.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5b395f2d"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_mae',    # –º–µ—Ç—Ä–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º\n",
        "    mode='min',            # –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—à–∏–±–∫–∏\n",
        "    patience=3,            # —Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö –∂–¥–∞—Ç—å –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if TRAIN_MODELS and not os.path.exists('models/clip_vit_b32.ckpt'):\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    model = CompositionLitModel('vit_base_patch16_clip_224.openai', lr=LR, task_type='both')\n",
        "    if loss_type == 'class_balanced':\n",
        "        dm.setup()\n",
        "        y_bin = (dm.df_train.iloc[:, 1:] > 0).astype(int).values\n",
        "        model.set_class_weights(y_bin)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        default_root_dir='.',\n",
        "        devices=1,\n",
        "        accelerator=device,\n",
        "        callbacks=[early_stop])\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.save_checkpoint('models/clip_vit_b32.ckpt')\n",
        "else:\n",
        "    print(\"‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞: models/clip_vit_b32.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfVJbq5-1W3L"
      },
      "source": [
        "–ê–Ω—Å–∞–º–±–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T9LzeDq81Yd0"
      },
      "outputs": [],
      "source": [
        "# === 1. –ü—É—Ç–∏ –∫ —á–µ–∫–ø–æ–π–Ω—Ç–∞–º –º–æ–¥–µ–ª–µ–π ===\n",
        "ckpts = {\n",
        "    'vitb16':    'models/vit_b16.ckpt',\n",
        "    'efnb3':     'models/efficientnet_b3.ckpt',\n",
        "    'resnet50':  'models/resnet50.ckpt'\n",
        "}\n",
        "\n",
        "# === 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π ===\n",
        "if all(os.path.exists(path) for path in ckpts.values()):\n",
        "    print(\"‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–≥—Ä—É–∂–∞–µ–º...\")\n",
        "\n",
        "    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
        "    models = {\n",
        "        name: CompositionLitModel.load_from_checkpoint(path).eval().to(device)\n",
        "        for name, path in ckpts.items()\n",
        "    }\n",
        "\n",
        "    # === 3. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∞–Ω—Å–∞–º–±–ª—è ===\n",
        "    @torch.no_grad()\n",
        "    def ensemble_predict(dl):\n",
        "        all_preds, all_targets = [], []\n",
        "        for x, y in dl:\n",
        "            x = x.to(device)\n",
        "            preds_list = [model(x)['regression'] for model in models.values()]\n",
        "            ensemble = torch.stack(preds_list).mean(dim=0)\n",
        "            all_preds.append(ensemble.cpu())\n",
        "            all_targets.append(y)\n",
        "        return torch.cat(all_preds), torch.cat(all_targets)\n",
        "\n",
        "    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "    dm = CompositionDataModule(CSV_PATH, IMG_SIZE, BATCH_SIZE)\n",
        "    dm.setup()\n",
        "    val_dl = dm.val_dataloader()\n",
        "    ens_preds, targets = ensemble_predict(val_dl)\n",
        "\n",
        "    # === 4. –ú–µ—Ç—Ä–∏–∫–∏ ===\n",
        "    mae_mean = mean_absolute_error(targets.numpy(), ens_preds.numpy())\n",
        "    mae_per_rule = torch.mean(torch.abs(ens_preds - targets), dim=0).numpy()\n",
        "\n",
        "    print(f\"üìä MAE –∞–Ω—Å–∞–º–±–ª—è (—Å—Ä–µ–¥–Ω–µ–µ): {mae_mean:.4f}\")\n",
        "    for i, mae in enumerate(mae_per_rule):\n",
        "        print(f\"Rule {i+1:02d}: MAE = {mae:.4f}\")\n",
        "\n",
        "    # === 5. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç—Ä–∏–∫ ===\n",
        "    if \"metrics_df\" not in locals():\n",
        "        metrics_df = pd.DataFrame(columns=[\"model\", \"val_mae\", \"val_cls_acc\"])\n",
        "    metrics_df.loc[len(metrics_df)] = ['ensemble_vit_effnet_resnet', mae_mean, np.nan]\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –ù–µ –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ –∞–Ω—Å–∞–º–±–ª—è:\")\n",
        "    for name, path in ckpts.items():\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"  ‚õî –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHXd_Uhm1buN"
      },
      "source": [
        "SVM –Ω–∞ —Ñ–∏—á–∞—Ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzQJLZ771dd4"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "SVR_MODEL_DIR = 'models/svr_vitb16'\n",
        "os.makedirs(SVR_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# === 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∏–∑ ViT-B/16 ===\n",
        "feature_extractor = models['vitb16'].backbone\n",
        "feature_extractor.eval().to(device)\n",
        "\n",
        "X_train, Y_train = [], []\n",
        "for x, y in dm.train_dataloader():\n",
        "    with torch.no_grad():\n",
        "        feats = feature_extractor(x.to(device))\n",
        "    X_train.append(feats.cpu().numpy())\n",
        "    Y_train.append(y.numpy())\n",
        "\n",
        "X_train = np.vstack(X_train)\n",
        "Y_train = np.vstack(Y_train)\n",
        "\n",
        "# === 2. –û–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π SVR ===\n",
        "svm_models = []\n",
        "retrained = False\n",
        "\n",
        "if TRAIN_MODELS and not all(os.path.exists(f'{SVR_MODEL_DIR}/rule_{i+1:02d}.joblib') for i in range(13)):\n",
        "    print(\"üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π SVR...\")\n",
        "\n",
        "    for i in range(13):\n",
        "        # –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ –ø–æ–¥–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è —É–ø—Ä–æ—â—ë–Ω–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ \"early stopping\"\n",
        "        X_subtrain, X_subval, y_subtrain, y_subval = train_test_split(\n",
        "            X_train, Y_train[:, i], test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        best_mae = float('inf')\n",
        "        best_model = None\n",
        "\n",
        "        for c_val in [0.1, 1.0, 10.0]:  # –∞–Ω–∞–ª–æ–≥ –ø–æ–¥–±–æ—Ä–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–µ\n",
        "            model = SVR(kernel='rbf', C=c_val, epsilon=0.1)\n",
        "            model.fit(X_subtrain, y_subtrain)\n",
        "            pred_val = model.predict(X_subval)\n",
        "            mae = mean_absolute_error(y_subval, pred_val)\n",
        "            if mae < best_mae:\n",
        "                best_mae = mae\n",
        "                best_model = model\n",
        "\n",
        "        joblib.dump(best_model, f'{SVR_MODEL_DIR}/rule_{i+1:02d}.joblib')\n",
        "        svm_models.append(best_model)\n",
        "        print(f\"Rule {i+1:02d} ‚Äî best C={best_model.C}, val MAE={best_mae:.4f}\")\n",
        "\n",
        "    retrained = True\n",
        "else:\n",
        "    print(\"‚úÖ –ú–æ–¥–µ–ª–∏ SVR —É–∂–µ –æ–±—É—á–µ–Ω—ã. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤...\")\n",
        "    for i in range(13):\n",
        "        model = joblib.load(f'{SVR_MODEL_DIR}/rule_{i+1:02d}.joblib')\n",
        "        svm_models.append(model)\n",
        "\n",
        "# === 3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ===\n",
        "X_val, Y_val = [], []\n",
        "for x, y in dm.val_dataloader():\n",
        "    with torch.no_grad():\n",
        "        feats = feature_extractor(x.to(device))\n",
        "    X_val.append(feats.cpu().numpy())\n",
        "    Y_val.append(y.numpy())\n",
        "\n",
        "X_val = np.vstack(X_val)\n",
        "Y_val = np.vstack(Y_val)\n",
        "\n",
        "# === 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –º–µ—Ç—Ä–∏–∫–∏ ===\n",
        "preds_val = np.stack([svm.predict(X_val) for svm in svm_models], axis=1)\n",
        "mae_svm = mean_absolute_error(Y_val, preds_val)\n",
        "mae_per_rule = np.mean(np.abs(preds_val - Y_val), axis=0)\n",
        "\n",
        "print(f\"üìä SVR (ViT) MAE (—Å—Ä–µ–¥–Ω–µ–µ): {mae_svm:.4f}\")\n",
        "for i, mae in enumerate(mae_per_rule):\n",
        "    print(f\"Rule {i+1:02d}: MAE = {mae:.4f}\")\n",
        "\n",
        "# === 5. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –æ–±—â—É—é —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç—Ä–∏–∫ ===\n",
        "if \"metrics_df\" not in locals():\n",
        "    metrics_df = pd.DataFrame(columns=[\"model\", \"val_mae\", \"val_cls_acc\"])\n",
        "\n",
        "metrics_df.loc[len(metrics_df)] = ['svm_vitb16_features', mae_svm, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vx-gwyw6F73"
      },
      "source": [
        "–£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8b4c2874"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_model(model, dataloader, device='cuda'):\n",
        "    preds_reg, preds_cls, targets = [], [], []\n",
        "    is_torch_model = isinstance(model, torch.nn.Module)\n",
        "    if is_torch_model:\n",
        "        model.eval().to(device)\n",
        "    for x, y in dataloader:\n",
        "        if is_torch_model:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "        out = model(x)\n",
        "        targets.append(y.cpu() if is_torch_model else y)\n",
        "        if 'regression' in out:\n",
        "            preds_reg.append(out['regression'].detach().cpu() if is_torch_model else out['regression'])\n",
        "        if 'classification' in out:\n",
        "            preds_cls.append(torch.sigmoid(out['classification'].detach().cpu()) if is_torch_model else out['classification'])\n",
        "    result = {}\n",
        "    if preds_reg:\n",
        "        result['regression'] = torch.cat(preds_reg, dim=0)\n",
        "    if preds_cls:\n",
        "        result['classification'] = torch.cat(preds_cls, dim=0)\n",
        "    result['target'] = torch.cat(targets, dim=0)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxAyfYnX1iHW"
      },
      "source": [
        "–°–±–æ—Ä –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lHGpScYD4Yjl"
      },
      "outputs": [],
      "source": [
        "class SVMWrapper:\n",
        "    def __init__(self, models, feature_extractor, device='cuda'):\n",
        "        self.models = models\n",
        "        self.feature_extractor = feature_extractor.eval().to(device)\n",
        "        self.device = device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, x):\n",
        "        feats = self.feature_extractor(x.to(self.device)).cpu().numpy()\n",
        "        preds = np.stack([m.predict(feats) for m in self.models], axis=1)\n",
        "        return {'regression': torch.tensor(preds, dtype=torch.float32)}\n",
        "\n",
        "class EnsembleWrapper:\n",
        "    def __init__(self, models_dict, device='cuda'):\n",
        "        self.models = {k: m.eval().to(device) for k, m in models_dict.items()}\n",
        "        self.device = device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, x):\n",
        "        x = x.to(self.device)\n",
        "        preds = [m(x)['regression'] for m in self.models.values()]\n",
        "        mean_preds = torch.stack(preds).mean(dim=0)\n",
        "        return {'regression': mean_preds}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d38a53e"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_model(name, model, dataloader):\n",
        "    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ eval –∏ –ø–µ—Ä–µ–Ω–æ—Å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è torch-–º–æ–¥–µ–ª–µ–π\n",
        "    if isinstance(model, torch.nn.Module):\n",
        "        model.eval().to(device)\n",
        "\n",
        "    all_targets, all_reg_preds, all_cls_preds = [], [], []\n",
        "\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        all_targets.append(y.cpu())\n",
        "\n",
        "        if 'regression' in output:\n",
        "            all_reg_preds.append(output['regression'].cpu())\n",
        "        if 'classification' in output:\n",
        "            all_cls_preds.append(output['classification'].cpu())\n",
        "\n",
        "    scores = {'model': name}\n",
        "    y_true = torch.cat(all_targets).numpy()\n",
        "\n",
        "    # MAE + RMSE\n",
        "    if all_reg_preds:\n",
        "        y_pred = torch.cat(all_reg_preds).numpy()\n",
        "        scores['MAE'] = mean_absolute_error(y_true, y_pred)\n",
        "        scores['RMSE'] = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    # Accuracy (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –ø–æ classification, –∏–Ω–∞—á–µ –ø–æ threshold –æ—Ç regression)\n",
        "    if all_cls_preds:\n",
        "        y_pred_cls = torch.cat(all_cls_preds).numpy() > 0.5\n",
        "        y_true_cls = y_true > 0\n",
        "        scores['Accuracy'] = accuracy_score(y_true_cls.flatten(), y_pred_cls.flatten())\n",
        "    elif all_reg_preds:\n",
        "        y_pred_cls = y_pred > 0\n",
        "        y_true_cls = y_true > 0\n",
        "        scores['Accuracy'] = accuracy_score(y_true_cls.flatten(), y_pred_cls.flatten())\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def benchmark_all(models_dict, dataloader):\n",
        "    metrics = []\n",
        "\n",
        "    for name, model in models_dict.items():\n",
        "        print(f\"üîç –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {name}\")\n",
        "\n",
        "        # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è —Ç–æ–ª—å–∫–æ –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å\n",
        "        start = time.time()\n",
        "        scores = evaluate_model(name, model, dataloader)\n",
        "        duration = time.time() - start\n",
        "\n",
        "        # –ü–æ–¥—Å—á—ë—Ç latency (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞)\n",
        "        try:\n",
        "            num_samples = len(dataloader.dataset)\n",
        "            scores['Latency (ms/img)'] = 1000 * duration / num_samples\n",
        "        except Exception as e:\n",
        "            scores['Latency (ms/img)'] = None\n",
        "            print(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å latency: {e}\")\n",
        "\n",
        "        metrics.append(scores)\n",
        "\n",
        "        # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥\n",
        "        print(f\"‚úÖ {name}: MAE={scores.get('MAE', '‚Äî')}, Accuracy={scores.get('Accuracy', '‚Äî')}, Latency={scores['Latency (ms/img)']:.2f} ms\")\n",
        "\n",
        "    return pd.DataFrame(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAeGvZyh67cW"
      },
      "source": [
        "AutoModelSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "360234fa"
      },
      "outputs": [],
      "source": [
        "def normalize_column(df, column, inverse=False):\n",
        "    col = df[column].copy()\n",
        "    if col.isnull().all():\n",
        "        return pd.Series([0.0] * len(df))\n",
        "    col = (col - col.min()) / (col.max() - col.min() + 1e-8)\n",
        "    return 1.0 - col if inverse else col\n",
        "\n",
        "def compute_total_score(df, weights={'MAE': 0.5, 'Accuracy': 0.4, 'Latency': 0.1}):\n",
        "    norm_mae = normalize_column(df, 'MAE', inverse=True)\n",
        "    norm_acc = normalize_column(df, 'Accuracy')\n",
        "    norm_latency = normalize_column(df, 'Latency (ms/img)', inverse=True)\n",
        "\n",
        "    total = (\n",
        "        weights['MAE'] * norm_mae +\n",
        "        weights['Accuracy'] * norm_acc +\n",
        "        weights['Latency'] * norm_latency\n",
        "    )\n",
        "    return total\n",
        "\n",
        "def select_best_model(df: pd.DataFrame):\n",
        "    df_copy = df.copy()\n",
        "    df_copy['total_score'] = compute_total_score(df_copy)\n",
        "    df_sorted = df_copy.sort_values(by='total_score', ascending=False)\n",
        "    best_model_row = df_sorted.iloc[0]\n",
        "    return df_sorted, best_model_row\n",
        "\n",
        "\n",
        "# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ===\n",
        "model_dict = {\n",
        "    'ResNet50': CompositionLitModel.load_from_checkpoint('models/resnet50.ckpt'),\n",
        "    'EffNet-B3': CompositionLitModel.load_from_checkpoint('models/efficientnet_b3.ckpt'),\n",
        "    'ViT-B/16': CompositionLitModel.load_from_checkpoint('models/vit_b16.ckpt'),\n",
        "    'CLIP ViT-B/32': CompositionLitModel.load_from_checkpoint('models/clip_vit_b32.ckpt'),\n",
        "}\n",
        "for m in model_dict.values():\n",
        "    m.to(device)\n",
        "\n",
        "# SVM\n",
        "svm_model = SVMWrapper(svm_models, feature_extractor=models['vitb16'].backbone, device=device)\n",
        "model_dict['SVM (ViT features)'] = svm_model\n",
        "\n",
        "# Ensemble\n",
        "ensemble_model = EnsembleWrapper({\n",
        "    'resnet50': model_dict['ResNet50'],\n",
        "    'efnb3': model_dict['EffNet-B3'],\n",
        "    'vitb16': model_dict['ViT-B/16'],\n",
        "})\n",
        "model_dict['Ensemble (ResNet+EffNet+ViT)'] = ensemble_model\n",
        "\n",
        "# === –û—Ü–µ–Ω–∫–∞ ===\n",
        "df_metrics = benchmark_all(model_dict, dm.val_dataloader())\n",
        "df_metrics.to_csv('results/model_comparison.csv', index=False)\n",
        "\n",
        "# === –†–µ–π—Ç–∏–Ω–≥ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π ===\n",
        "df_ranked, best_model_row = select_best_model(df_metrics)\n",
        "df_ranked.to_csv('results/ranked_models.csv', index=False)\n",
        "\n",
        "# === –í—ã–≤–æ–¥ ===\n",
        "print(\"ü•á Best model overall:\")\n",
        "display(best_model_row.to_frame().T)\n",
        "BEST_MODEL_NAME = best_model_row['model']\n",
        "BEST_MODEL = model_dict[BEST_MODEL_NAME]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e634505"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    \"\"\"–ó–∞–º–µ–Ω—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.\"\"\"\n",
        "    return re.sub(r'[^a-zA-Z0-9_.-]', '_', name)\n",
        "\n",
        "def save_best_model(model, name: str, save_dir: str = \"models\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    safe_name = sanitize_filename(name)\n",
        "\n",
        "    path_ckpt = os.path.join(save_dir, f\"best_model_{safe_name}.ckpt\")\n",
        "    path_pt = os.path.join(save_dir, f\"best_model_{safe_name}.pt\")\n",
        "    path_full = os.path.join(save_dir, f\"best_model_{safe_name}_full.pt\")\n",
        "\n",
        "    if isinstance(model, pl.LightningModule):\n",
        "        model = model.cpu().eval()\n",
        "        try:\n",
        "            model.save_checkpoint(path_ckpt)\n",
        "            print(f\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ Lightning checkpoint: {path_ckpt}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ .ckpt: {e}\")\n",
        "\n",
        "        try:\n",
        "            torch.save(model.state_dict(), path_pt)\n",
        "            print(f\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ç–æ–ª—å–∫–æ state_dict: {path_pt}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ state_dict: {e}\")\n",
        "\n",
        "        try:\n",
        "            torch.save(model, path_full)\n",
        "            print(f\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ –ø–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å: {path_full}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}\")\n",
        "\n",
        "    elif isinstance(model, SVMWrapper):\n",
        "        path_svm = os.path.join(save_dir, f\"{safe_name}_svm.joblib\")\n",
        "        try:\n",
        "            joblib.dump(model, path_svm)\n",
        "            print(f\"üíæ –°–æ—Ö—Ä–∞–Ω—ë–Ω SVMWrapper: {path_svm}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ SVMWrapper: {e}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {type(model)}. –ü—Ä–æ–ø—É—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.\")\n",
        "\n",
        "# === –í—ã–∑–æ–≤ ===\n",
        "save_best_model(BEST_MODEL, BEST_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4cbbf06"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_reliability(y_true, y_prob, title='Reliability Diagram'):\n",
        "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# –û—Ü–µ–Ω–∏–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –ø–æ –≤—Å–µ–º –ø—Ä–∞–≤–∏–ª–∞–º\n",
        "res = predict_model(BEST_MODEL, dm.test_dataloader(), device=device)\n",
        "if 'classification' in res:\n",
        "    y_true_bin = (res['target'] > 0).numpy()\n",
        "    y_pred_prob = res['classification'].numpy()\n",
        "\n",
        "    for i in range(min(5, y_true_bin.shape[1])):  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∞–≤–∏–ª\n",
        "        plot_reliability(y_true_bin[:, i], y_pred_prob[:, i], title=f'Rule {i+1} calibration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "607611c0"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# –û—Ç—á—ë—Ç: –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º\n",
        "def plot_metric(df, metric_name, title=None, save_path=None):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(x='model', y=metric_name, data=df, palette='viridis')\n",
        "    plt.title(title or metric_name)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.grid(True)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "plot_metric(df_ranked, 'MAE', '–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAE)', 'results/plot_mae.png')\n",
        "plot_metric(df_ranked, 'RMSE', '–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (RMSE)', 'results/plot_rmse.png')\n",
        "if 'Accuracy' in df_ranked.columns:\n",
        "    plot_metric(df_ranked, 'Accuracy', '–¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (Accuracy)', 'results/plot_accuracy.png')\n",
        "plot_metric(df_ranked, 'Latency (ms/img)', '–°–∫–æ—Ä–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞', 'results/plot_latency.png')\n",
        "plot_metric(df_ranked, 'total_score', '–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π', 'results/plot_score.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b57de982"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def generate_comparative_report(df):\n",
        "    summary = []\n",
        "\n",
        "    best_mae = df.sort_values('MAE').iloc[0]\n",
        "    best_rmse = df.sort_values('RMSE').iloc[0]\n",
        "    best_acc = df.sort_values('Accuracy', ascending=False).iloc[0] if 'Accuracy' in df.columns else None\n",
        "    best_latency = df.sort_values('Latency (ms/img)').iloc[0]\n",
        "    best_total = df.sort_values('total_score', ascending=False).iloc[0]\n",
        "\n",
        "    summary.append(f\"**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ MAE:** {best_mae['model']} ({best_mae['MAE']:.4f})\")\n",
        "    summary.append(f\"**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ RMSE:** {best_rmse['model']} ({best_rmse['RMSE']:.4f})\")\n",
        "    if best_acc is not None:\n",
        "        summary.append(f\"**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ Accuracy:** {best_acc['model']} ({best_acc['Accuracy']:.4f})\")\n",
        "    summary.append(f\"**–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å:** {best_latency['model']} ({best_latency['Latency (ms/img)']:.2f} ms/img)\")\n",
        "    summary.append(f\"**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ —Å–æ–≤–æ–∫—É–ø–Ω–æ–π –æ—Ü–µ–Ω–∫–µ:** {best_total['model']} (score: {best_total['total_score']:.4f})\")\n",
        "\n",
        "    display(Markdown(\"### üìä –°–≤–æ–¥–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç\"))\n",
        "    for line in summary:\n",
        "        display(Markdown(\"- \" + line))\n",
        "\n",
        "generate_comparative_report(df_ranked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TXOQ5uVUIHW"
      },
      "source": [
        "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOl6MMTO6HhE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class RegressionChannelWrapper(nn.Module):\n",
        "    def __init__(self, model, channel_index=0):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.channel_index = channel_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out['regression'][:, self.channel_index].unsqueeze(1)\n",
        "\n",
        "def get_last_conv_layer(model):\n",
        "    if hasattr(model, 'layer4'):\n",
        "        return model.layer4[-1], False\n",
        "    elif hasattr(model, 'blocks'):\n",
        "        return model.blocks[-1], True\n",
        "    elif hasattr(model, 'conv_head'):\n",
        "        return model.conv_head, False\n",
        "    else:\n",
        "        raise ValueError(\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π conv-—Å–ª–æ–π.\")\n",
        "\n",
        "def reshape_transform_vit(tensor, height=14, width=14):\n",
        "    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, tensor.size(2))\n",
        "    return result.permute(0, 3, 1, 2)\n",
        "\n",
        "# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "rule_index = 0  # \"center\"\n",
        "wrapped_model = RegressionChannelWrapper(BEST_MODEL, channel_index=rule_index).to(device)\n",
        "target_layer, use_vit = get_last_conv_layer(BEST_MODEL.backbone)\n",
        "reshape_transform = reshape_transform_vit if use_vit else None\n",
        "\n",
        "cam = GradCAM(model=wrapped_model,\n",
        "              target_layers=[target_layer],\n",
        "              reshape_transform=reshape_transform)\n",
        "\n",
        "best_score = -1\n",
        "best_img_rgb = None\n",
        "best_heatmap = None\n",
        "\n",
        "# --- –ü—Ä–æ—Ö–æ–¥ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
        "for imgs, ys in dm.val_dataloader():\n",
        "    for i in range(imgs.size(0)):\n",
        "        img = imgs[i].unsqueeze(0).to(device)\n",
        "        rgb = imgs[i].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        grayscale = cam(input_tensor=img)[0]\n",
        "\n",
        "        # –û—Ü–µ–Ω–∫–∞: —Å–∫–æ–ª—å–∫–æ \"–≤–Ω–∏–º–∞–Ω–∏—è\" –≤ —Ü–µ–Ω—Ç—Ä–µ\n",
        "        h, w = grayscale.shape\n",
        "        ch, cw = h // 3, w // 3\n",
        "        center_mask = np.zeros_like(grayscale)\n",
        "        center_mask[h//3:2*h//3, w//3:2*w//3] = 1\n",
        "        center_score = (grayscale * center_mask).sum() / grayscale.sum()\n",
        "\n",
        "        if center_score > best_score:\n",
        "            best_score = center_score\n",
        "            best_img_rgb = rgb\n",
        "            best_heatmap = show_cam_on_image(rgb, grayscale, use_rgb=True)\n",
        "\n",
        "    # –æ–≥—Ä–∞–Ω–∏—á–∏–º –æ–¥–Ω–∏–º –±–∞—Ç—á–µ–º, –µ—Å–ª–∏ –¥–æ–ª–≥–æ:\n",
        "    break\n",
        "\n",
        "# --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞\n",
        "plt.imshow(best_heatmap)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Grad-CAM: —Ü–µ–Ω—Ç—Ä –≤–Ω–∏–º–∞–Ω–∏—è –≤ —Ü–µ–Ω—Ç—Ä–µ (score={best_score:.2f})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f18c128b"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –≤—ã–±–æ—Ä–æ–º –æ–¥–Ω–æ–≥–æ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞\n",
        "class RegressionChannelWrapper(nn.Module):\n",
        "    def __init__(self, model, channel_index=0):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.channel_index = channel_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out['regression'][:, self.channel_index].unsqueeze(1)\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è + —è–≤–ª—è–µ—Ç—Å—è –ª–∏ ViT\n",
        "def get_last_conv_layer(model):\n",
        "    if hasattr(model, 'layer4'):\n",
        "        return model.layer4[-1], False  # ResNet\n",
        "    elif hasattr(model, 'blocks'):\n",
        "        return model.blocks[-1], True   # ViT / CLIP\n",
        "    elif hasattr(model, 'conv_head'):\n",
        "        return model.conv_head, False   # EfficientNet\n",
        "    else:\n",
        "        raise ValueError(\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π conv-—Å–ª–æ–π –º–æ–¥–µ–ª–∏.\")\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è ViT: [B, N, C] ‚Üí [B, C, H, W]\n",
        "def reshape_transform_vit(tensor, height=14, width=14):\n",
        "    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, tensor.size(2))\n",
        "    result = result.permute(0, 3, 1, 2)  # [B, C, H, W]\n",
        "    return result\n",
        "\n",
        "# –ü—Ä–∏–∑–Ω–∞–∫ 0 (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"center\")\n",
        "rule_index = 0\n",
        "wrapped_model = RegressionChannelWrapper(BEST_MODEL, channel_index=rule_index).to(device)\n",
        "target_layer, use_vit = get_last_conv_layer(BEST_MODEL.backbone)\n",
        "reshape_transform = reshape_transform_vit if use_vit else None\n",
        "\n",
        "cam = GradCAM(\n",
        "    model=wrapped_model,\n",
        "    target_layers=[target_layer],\n",
        "    reshape_transform=reshape_transform\n",
        ")\n",
        "\n",
        "imgs, ys = next(iter(dm.val_dataloader()))\n",
        "img = imgs[0].unsqueeze(0).to(device)\n",
        "rgb = imgs[0].permute(1, 2, 0).numpy()\n",
        "\n",
        "grayscale = cam(input_tensor=img)[0]\n",
        "heatmap = show_cam_on_image(rgb, grayscale, use_rgb=True)\n",
        "\n",
        "plt.imshow(heatmap)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Grad-CAM | –ü—Ä–∏–∑–Ω–∞–∫ {rule_index + 1}\")\n",
        "plt.savefig(\"results/gradcam_vit.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4favj5r1mp9"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import torch.nn as nn\n",
        "\n",
        "# –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
        "class SHAPWrapper(nn.Module):\n",
        "    def __init__(self, model, channel_index=0):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.channel_index = channel_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.model(x)\n",
        "        return out['regression'][:, self.channel_index].unsqueeze(1)\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞\n",
        "rule_index = 0  # –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ü–µ–Ω—Ç—Ä\n",
        "shap_model = SHAPWrapper(BEST_MODEL, channel_index=rule_index).to(device)\n",
        "\n",
        "# –î–∞–Ω–Ω—ã–µ\n",
        "background = next(iter(dm.train_dataloader()))[0][:16].to(device)\n",
        "test_imgs, _ = next(iter(dm.val_dataloader()))\n",
        "test_imgs = test_imgs[:5].to(device)\n",
        "\n",
        "# SHAP (–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π)\n",
        "e = shap.GradientExplainer(shap_model, background)\n",
        "shap_vals = e.shap_values(test_imgs)\n",
        "\n",
        "# –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ [B, H, W, C]\n",
        "test_imgs_nhwc = test_imgs.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º: (5, 3, 224, 224, 1) ‚Üí (5, 224, 224, 3)\n",
        "shap_vals_correct = shap_vals.transpose(0, 2, 3, 1, 4).squeeze(-1)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "shap.image_plot([shap_vals_correct], test_imgs_nhwc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d23daa0b"
      },
      "outputs": [],
      "source": [
        "# SHAP summary plot (SVM –Ω–∞ ViT)\n",
        "import joblib\n",
        "svms = [joblib.load(f'models/svr_vitb16/rule_{i+1:02d}.joblib') for i in range(13)]\n",
        "feature_extractor = models['vitb16'].backbone.eval().to(device)\n",
        "\n",
        "X_val = []\n",
        "for x, y in dm.val_dataloader():\n",
        "    with torch.no_grad():\n",
        "        feats = feature_extractor(x.to(device)).cpu().numpy()\n",
        "    X_val.append(feats)\n",
        "X_val = np.vstack(X_val)\n",
        "\n",
        "explainer = shap.Explainer(svms[0].predict, X_val)\n",
        "shap_vals = explainer(X_val[:100])\n",
        "\n",
        "shap.summary_plot(shap_vals.values, X_val[:100], feature_names=[f\"f{i+1}\" for i in range(X_val.shape[1])], show=False)\n",
        "plt.savefig('results/shap_summary.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2t7_N-p7HuA"
      },
      "outputs": [],
      "source": [
        "ranking.plot(x='model', y='score', kind='bar', legend=False)\n",
        "plt.title('–°–≤–æ–¥–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π')\n",
        "plt.ylabel('Score')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}